
import streamlit as st
import pandas as pd
import numpy as np
from darts import TimeSeries
from darts.metrics import mae, mape, r2_score, rmse, mse
import warnings
import plotly.graph_objects as go
import plotly.io as pio
import streamlit.components.v1 as components
import time
import os

try:
    import psutil
except ImportError:
    psutil = None
pio.templates.default = "plotly_dark"
from models_lib import MODELS, train_model, optimize_hyperparameters
from utils import (
    plot_decomposition,
    plot_forecast,
    plot_final_forecast,
    create_excel_download,
    recommend_metric,
)

# --- Page Config ---
st.set_page_config(
    page_title="–ë–∏—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤",
    page_icon="‚öîÔ∏è",
    layout="wide",
)

# --- Warnings ---
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

# --- Helpers ---
MAX_ROWS = 5000

# –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —á–∏—Å–ª–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –º–∞—Ç—Ä–∏—á–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ –Ω–∞ —Å–ª–∞–±—ã—Ö —Å–µ—Ä–≤–µ—Ä–∞—Ö
os.environ.setdefault("OMP_NUM_THREADS", "1")
os.environ.setdefault("MKL_NUM_THREADS", "1")
os.environ.setdefault("NUMEXPR_NUM_THREADS", "1")

def adjust_daily_to_monthly(freq, index):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —á–∞—Å—Ç–æ—Ç—É –±–µ–∑ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π.
    """
    return freq, False  # None –∏–ª–∏ –Ω–∞–π–¥–µ–Ω–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –±–µ–∑ –ø–æ–¥–º–µ–Ω—ã

def normalize_month_start(df, time_col, freq):
    """
    –ë–µ–∑ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π ‚Äî –≤–µ—Ä–Ω—ë–º –∫–∞–∫ –µ—Å—Ç—å.
    """
    return df

def safe_timeseries_from_df(df, time_col, value_col, freq, label=""):
    """
    –°–æ–∑–¥–∞—ë—Ç TimeSeries —Å –ø–æ–ø—ã—Ç–∫–æ–π –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏ –ø–æ freq, –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –ø—Ä–æ–±—É–µ—Ç freq=None,
    –∏ –≤ —Ñ–∏–Ω–∞–ª–µ —Å—Ç—Ä–æ–∏—Ç –±–µ–∑ fill_missing_dates.
    """
    try:
        return TimeSeries.from_dataframe(
            df,
            time_col=time_col,
            value_cols=value_col,
            fill_missing_dates=True,
            freq=freq,
        )
    except Exception as e1:
        if label:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É ({freq}) –¥–ª—è {label}: {e1}. –ü—Ä–æ–±—É—é –±–µ–∑ freq.")
        try:
            return TimeSeries.from_dataframe(
                df,
                time_col=time_col,
                value_cols=value_col,
                fill_missing_dates=True,
                freq=None,
            )
        except Exception as e2:
            if label:
                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–æ–ª–Ω–∏—Ç—å –¥–∞—Ç—ã –¥–ª—è {label} –¥–∞–∂–µ –±–µ–∑ freq: {e2}. –°—Ç—Ä–æ—é –±–µ–∑ fill_missing_dates.")
            return TimeSeries.from_dataframe(
                df,
                time_col=time_col,
                value_cols=value_col,
                fill_missing_dates=False,
            )

def render_resource_panel(start_time=None):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ–º –±—ã—Å—Ç—Ä—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ—Å—É—Ä—Å–∞—Ö –≤ —Å–∞–π–¥–±–∞—Ä–µ."""
    with st.sidebar:
        st.markdown("### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
        if psutil:
            proc = psutil.Process()
            cpu = psutil.cpu_percent(interval=0.1)
            mem = proc.memory_info().rss / (1024 ** 2)
            sys_mem = psutil.virtual_memory()
            st.write(f"CPU: {cpu:.1f}%")
            st.write(f"RAM: {mem:.1f} MB / {(sys_mem.total/(1024**3)):.1f} GB")
        else:
            st.write("psutil –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        if start_time:
            elapsed = time.time() - start_time
            st.write(f"–í—Ä–µ–º—è —Å –∑–∞–ø—É—Å–∫–∞: {elapsed/60:.1f} –º–∏–Ω")

# --- Session State Management ---
def init_session_state():
    """Initializes session state variables if they don't exist."""
    defaults = {
        "screen": "upload",
        "df": None,
        "time_col": None,
        "value_col": None,
        "extra_cols": [],
        "n_forecast": 12,
        "season_period": 12,
        "ranking_metric": "MAPE",
        "ranking_metric_user_set": False,
        "use_hyperopt": False,
        "n_trials": 10,
        "battle_results": None,
        "trained_models": None,
        "forecasts": None,
        "final_forecast": None,
        "manual_date_col": None,
        "scroll_to_top": False,
        "val_size": None,
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def reset_session():
    """Resets the session state to start over."""
    st.session_state.clear()
    init_session_state()

# --- Main App Logic ---
init_session_state()

# --- Scroll helper ---
if st.session_state.get("scroll_to_top"):
    components.html(
        """
        <script>
            (() => {
                const goTop = () => {
                    try { window.scrollTo({top: 0, behavior: 'smooth'}); } catch(e) {}
                    try { parent.window.scrollTo({top: 0, behavior: 'smooth'}); } catch(e) {}
                    try { document.documentElement.scrollTo({top: 0, behavior: 'smooth'}); } catch(e) {}
                    try { document.body.scrollTo({top: 0, behavior: 'smooth'}); } catch(e) {}
                };
                requestAnimationFrame(goTop);
                setTimeout(goTop, 50);
                setTimeout(goTop, 150);
            })();
        </script>
        """,
        height=0,
        width=0,
    )
    st.session_state.scroll_to_top = False

# --- SCREEN 1: UPLOAD ---
if st.session_state.screen == "upload":
    st.title("‚öîÔ∏è –ë–∏—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤")
    st.header("–®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞—à —Ñ–∞–π–ª")
    st.info("–ü–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω: –¥–∞—Ç—ã –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ –Ω—É–∂–Ω–æ–π —á–∞—Å—Ç–æ—Ç–µ, –ø—Ä–æ–ø—É—Å–∫–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã, –¥—É–±–ª–∏–∫–∞—Ç—ã —É–¥–∞–ª–µ–Ω—ã.")

    uploaded_file = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª", type=["csv", "xlsx"]
    )

    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith(".csv"):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)

            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —Å—Ç—Ä–æ–∫–∞–º –¥–ª—è —Å–ª–∞–±—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
            if len(df) > MAX_ROWS:
                st.warning(f"–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç {len(df)} —Å—Ç—Ä–æ–∫, –ª–∏–º–∏—Ç ‚Äî {MAX_ROWS}. –ù–∞ —Å–ª–∞–±–æ–º —Å–µ—Ä–≤–µ—Ä–µ —ç—Ç–æ –º–æ–∂–µ—Ç —É–ø–∞—Å—Ç—å.")
                if not st.button("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –ª–∏–º–∏—Ç", key="continue_over_limit"):
                    st.stop()

            # –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π—Ç–∏ —Å—Ç–æ–ª–±—Ü—ã —Å –¥–∞—Ç–∞–º–∏
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –≥–∏–±–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç
            for col in df.columns:
                if df[col].dtype == "object" or 'date' in col.lower() or 'time' in col.lower():
                    try:
                        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞—Ç
                        parsed = pd.to_datetime(df[col], infer_datetime_format=True, errors='coerce')
                        # –ï—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ –±–æ–ª–µ–µ 80% –∑–Ω–∞—á–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç–æ—Ç —Å—Ç–æ–ª–±–µ—Ü
                        if parsed.notna().sum() > len(df) * 0.8:
                            df[col] = parsed
                    except (ValueError, TypeError):
                        continue
                # –ü—Ä–æ–±—É–µ–º –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É –≥–æ–¥–∞ (—Ñ–æ—Ä–º–∞—Ç YYYY)
                if str(col).lower() in ["year", "–≥–æ–¥"] or pd.api.types.is_integer_dtype(df[col]):
                    parsed_year = pd.to_datetime(df[col], format="%Y", errors="coerce")
                    if parsed_year.notna().sum() > len(df) * 0.8:
                        df[col] = parsed_year

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –∑–∞–ø–æ–ª–Ω–∏—Ç—å –Ω–∞ —ç—Ç–∞–ø–µ –∑–∞–≥—Ä—É–∑–∫–∏
            total_missing = int(df.isna().sum().sum())
            if total_missing > 0:
                miss_cols = df.isna().sum()
                miss_cols = miss_cols[miss_cols > 0].to_dict()
                st.warning(f"–í —Ñ–∞–π–ª–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ ({total_missing} –∑–Ω–∞—á–µ–Ω–∏–π). –ö–æ–ª–æ–Ω–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏: {miss_cols}")
                if st.button("–ó–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏", key="fill_missing_upload"):
                    df_filled = df.copy()
                    num_cols = df_filled.select_dtypes(include=[np.number]).columns
                    for col in num_cols:
                        if df_filled[col].isna().any():
                            df_filled[col] = df_filled[col].interpolate(limit_direction="both")
                            df_filled[col] = df_filled[col].fillna(df_filled[col].mean(skipna=True))
                    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∑–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏/—Å–ª–µ–¥—É—é—â–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                    other_cols = [c for c in df_filled.columns if c not in num_cols]
                    if other_cols:
                        df_filled[other_cols] = df_filled[other_cols].ffill().bfill()
                    df = df_filled
                    st.success("–ü—Ä–æ–ø—É—Å–∫–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.")
            
            date_cols = [col for col in df.columns if pd.api.types.is_datetime64_any_dtype(df[col])]
            if date_cols:
                df.dropna(subset=date_cols, inplace=True)

            st.session_state.df = df
            st.session_state.screen = "setup"
            st.rerun()

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")

# --- SCREEN 2: SETUP ---
elif st.session_state.screen == "setup":
    st.title("–®–∞–≥ 2: –ê–Ω–∞–ª–∏–∑ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞")
    df = st.session_state.df

    if len(df) > 500:
        st.warning("‚ö†Ô∏è –§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª–µ–µ 500 —Å—Ç—Ä–æ–∫. –û–±—É—á–µ–Ω–∏–µ –∏ —Ä–∞—Å—á—ë—Ç—ã –º–æ–≥—É—Ç –∑–∞–Ω—è—Ç—å –∑–∞–º–µ—Ç–Ω–æ –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏.")

    st.subheader("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
    st.dataframe(df.head(5))
    
    # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ
    st.info(f"üìä **–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ:** –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {len(df)}, –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns)}")

    date_cols = [col for col in df.columns if pd.api.types.is_datetime64_any_dtype(df[col])]
    
    # –ï—Å–ª–∏ –¥–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –¥–∞–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —É–∫–∞–∑–∞—Ç—å –≤—Ä—É—á–Ω—É—é
    if not date_cols:
        st.warning("‚ö†Ô∏è –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∫–æ–ª–æ–Ω–æ–∫ —Å –¥–∞—Ç–∞–º–∏.")
        st.subheader("–£–∫–∞–∂–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É —Å –¥–∞—Ç–æ–π –≤—Ä—É—á–Ω—É—é:")
        manual_date_col = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π:", df.columns.tolist(), 
                                       index=0, key="manual_date_select")
        
        if st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç—É –∫–æ–ª–æ–Ω–∫—É"):
            try:
                # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ –¥–∞—Ç—É —Å —Ä–∞–∑–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏
                test_col = pd.to_datetime(df[manual_date_col], infer_datetime_format=True, errors='coerce')
                if test_col.notna().sum() > len(df) * 0.8:  # –ï—Å–ª–∏ –±–æ–ª—å—à–µ 80% —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ
                    df[manual_date_col] = test_col
                    date_cols = [manual_date_col]
                    st.session_state.df = df
                    st.success(f"‚úÖ –ö–æ–ª–æ–Ω–∫–∞ '{manual_date_col}' —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –∫–∞–∫ –¥–∞—Ç–∞!")
                    st.rerun()
                else:
                    st.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞—Ç—ã –≤ –∫–æ–ª–æ–Ω–∫–µ '{manual_date_col}'. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω.")
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ –¥–∞—Ç—ã: {e}")
        st.stop()
    
    # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–æ–π
    default_idx = 0
    if st.session_state.time_col in date_cols:
        default_idx = date_cols.index(st.session_state.time_col)
    st.session_state.time_col = st.selectbox("1. –í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º:", date_cols, index=default_idx)

    # –ü–æ–ª—É—á–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–∞
    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ —á–∏—Å–ª–∞
    potentially_numeric = []
    for col in df.columns:
        if col not in date_cols and col not in numeric_cols:
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ (—É—á–∏—Ç—ã–≤–∞—è –∑–∞–ø—è—Ç—ã–µ, –ø—Ä–æ–±–µ–ª—ã –∏ —Ç.–¥.)
            test_series = df[col].astype(str).str.replace(',', '', regex=False).str.replace(' ', '', regex=False).str.replace('$', '', regex=False)
            try:
                pd.to_numeric(test_series, errors='raise')
                potentially_numeric.append(col)
            except (ValueError, TypeError):
                pass
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    all_numeric_cols = numeric_cols + potentially_numeric
    available_value_cols = [col for col in all_numeric_cols if col != st.session_state.time_col]

    if not available_value_cols:
        st.error("–í —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        if st.button("–ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ"): reset_session(); st.rerun()
        st.stop()

    st.session_state.value_col = st.selectbox("2. –í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏:", available_value_cols, index=available_value_cols.index(st.session_state.value_col) if st.session_state.value_col in available_value_cols else 0)
    
    available_extra_cols = [col for col in all_numeric_cols if col not in [st.session_state.time_col, st.session_state.value_col]]
    st.session_state.extra_cols = st.multiselect("3. –í—ã–±–µ—Ä–∏—Ç–µ –¥–æ–ø. —Ñ–∞–∫—Ç–æ—Ä—ã (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ):", available_extra_cols, default=st.session_state.extra_cols)

    st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞")
    
    df_for_series = df.sort_values(by=st.session_state.time_col).copy()
    # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ –≥–æ–¥–∞ ‚Äî –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ –¥–∞—Ç—ã (–Ω–∞—á–∞–ª–æ –≥–æ–¥–∞)
    if not pd.api.types.is_datetime64_any_dtype(df_for_series[st.session_state.time_col]):
        if str(st.session_state.time_col).lower() in ["year", "–≥–æ–¥"]:
            df_for_series[st.session_state.time_col] = pd.to_datetime(df_for_series[st.session_state.time_col], format="%Y", errors="coerce")
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    dup_count = df_for_series.duplicated(subset=[st.session_state.time_col]).sum()
    if dup_count > 0:
        st.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ ({dup_count}). –û–Ω–∏ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã.")
        df_for_series = df_for_series.drop_duplicates(subset=[st.session_state.time_col], keep="first")

    # –û—á–∏—â–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç –∑–∞–ø—è—Ç—ã—Ö –∏ –¥—Ä—É–≥–∏—Ö —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
    if df_for_series[st.session_state.value_col].dtype == 'object':
        df_for_series[st.session_state.value_col] = df_for_series[st.session_state.value_col].astype(str).str.replace(',', '', regex=False).str.replace(' ', '', regex=False)
    df_for_series[st.session_state.value_col] = pd.to_numeric(df_for_series[st.session_state.value_col], errors='coerce')
    df_for_series.dropna(subset=[st.session_state.value_col], inplace=True)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º TimeSeries
    if len(df_for_series) < 3:
        st.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –¢—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 3 —Å—Ç—Ä–æ–∫–∏, –∞ —É –≤–∞—Å {len(df_for_series)}.")
        st.stop()
    
    # –ü—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    df_indexed = df_for_series.set_index(st.session_state.time_col).sort_index()
    inferred_freq = pd.infer_freq(df_indexed.index)
    inferred_freq, monthly_forced = adjust_daily_to_monthly(inferred_freq, df_indexed.index)
    
    # –ï—Å–ª–∏ —á–∞—Å—Ç–æ—Ç–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞, –ø—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ —Ä–∞–∑–Ω–∏—Ü–µ –º–µ–∂–¥—É –¥–∞—Ç–∞–º–∏
    if inferred_freq is None and len(df_indexed) > 1:
        time_diffs = df_indexed.index.to_series().diff().dropna()
        if len(time_diffs) > 0:
            median_diff = time_diffs.median()
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É –ø–æ –º–µ–¥–∏–∞–Ω–Ω–æ–π —Ä–∞–∑–Ω–∏—Ü–µ
            if pd.Timedelta(hours=23) <= median_diff <= pd.Timedelta(hours=25):
                inferred_freq = 'D'  # –î–Ω–µ–≤–Ω–∞—è
            elif pd.Timedelta(days=27) <= median_diff <= pd.Timedelta(days=32):
                inferred_freq = 'M'  # –ú–µ—Å—è—á–Ω–∞—è
            elif pd.Timedelta(hours=11) <= median_diff <= pd.Timedelta(hours=13):
                inferred_freq = 'H'  # –ß–∞—Å–æ–≤–∞—è
            else:
                inferred_freq = None
    
            if not monthly_forced:
                inferred_freq, monthly_forced = adjust_daily_to_monthly(inferred_freq, df_indexed.index)
    
    # –°–æ–∑–¥–∞–µ–º TimeSeries —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π –∏–ª–∏ –±–µ–∑ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤
    df_for_series = normalize_month_start(df_for_series, st.session_state.time_col, inferred_freq)
    series = safe_timeseries_from_df(
        df_for_series,
        time_col=st.session_state.time_col,
        value_col=st.session_state.value_col,
        freq=inferred_freq,
        label="–æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ä—è–¥–∞",
    )
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞—Å—Ç–æ—Ç–µ
    series_freq = pd.infer_freq(series.time_index)
    if series_freq or inferred_freq:
        freq_display = series_freq if series_freq else inferred_freq
        st.info(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞: {freq_display}")
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–∏–æ–¥ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–Ω–µ–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if inferred_freq == 'D' and st.session_state.get('freq_set_auto', False) is False:
            st.session_state.season_period = 7
            st.session_state.freq_set_auto = True
            st.rerun()
        elif inferred_freq == 'H' and st.session_state.get('freq_set_auto', False) is False:
            st.session_state.season_period = 24
            st.session_state.freq_set_auto = True
            st.rerun()
    else:
        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É —Ä—è–¥–∞. –ü–µ—Ä–∏–æ–¥ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Ä—É—á–Ω—É—é.")

    st.session_state.n_forecast = st.number_input("4. –£–∫–∞–∂–∏—Ç–µ —Å—Ä–æ–∫ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è (–≤ —à–∞–≥–∞—Ö):", min_value=1, value=st.session_state.n_forecast, step=1)
    st.session_state.season_period = st.number_input("5. –£–∫–∞–∂–∏—Ç–µ –ø–µ—Ä–∏–æ–¥ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏:", min_value=2, value=st.session_state.season_period, step=1)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
    cols_to_check = [st.session_state.value_col] + st.session_state.extra_cols
    missing_counts = {col: df_for_series[col].isna().sum() for col in cols_to_check}
    total_missing = sum(missing_counts.values())
    if total_missing > 0:
        st.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö: {missing_counts}")

        def has_trend(series_vals):
            vals = series_vals.dropna().to_numpy()
            if len(vals) < 3:
                return False
            x = np.arange(len(vals))
            slope = np.polyfit(x, vals, 1)[0]
            std = np.std(vals) + 1e-8
            return abs(slope) / std > 0.05

        trend_present = has_trend(df_for_series[st.session_state.value_col])
        suggested_method = "–∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–µ–π" if trend_present else "—Å—Ä–µ–¥–Ω–∏–º"
        st.info(f"–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏ {suggested_method} (—Ç—Ä–µ–Ω–¥ {'–æ–±–Ω–∞—Ä—É–∂–µ–Ω' if trend_present else '–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω'}).")

        if st.button("–ó–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"):
            for col in cols_to_check:
                if df_for_series[col].isna().any():
                    if trend_present:
                        df_for_series[col] = df_for_series[col].interpolate(limit_direction="both")
                    else:
                        mean_val = df_for_series[col].mean(skipna=True)
                        df_for_series[col] = df_for_series[col].fillna(mean_val)
            st.success("–ü—Ä–æ–ø—É—Å–∫–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã.")
    # –°—Ç—Ä–∞—Ö–æ–≤–∫–∞: –µ—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å NaN, –∑–∞–ø–æ–ª–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º, –∑–∞—Ç–µ–º —Å—Ä–µ–¥–Ω–∏–º
    if df_for_series[cols_to_check].isna().any().any():
        df_for_series[cols_to_check] = df_for_series[cols_to_check].ffill().bfill()
        for col in cols_to_check:
            if df_for_series[col].isna().any():
                df_for_series[col] = df_for_series[col].fillna(df_for_series[col].mean(skipna=True))

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª–µ –∏ –∫–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –¥–∞—Ç
    freq_guess = pd.infer_freq(df_for_series.sort_values(by=st.session_state.time_col)[st.session_state.time_col])
    if not freq_guess:
        diffs = df_for_series[st.session_state.time_col].sort_values().diff().dropna()
        if not diffs.empty:
            median_diff = diffs.median()
            if pd.Timedelta(days=27) <= median_diff <= pd.Timedelta(days=32):
                freq_guess = "M"
            elif pd.Timedelta(days=360) <= median_diff <= pd.Timedelta(days=380):
                freq_guess = "A"
    if freq_guess:
        full_index = pd.date_range(
            start=df_for_series[st.session_state.time_col].min(),
            end=df_for_series[st.session_state.time_col].max(),
            freq=freq_guess,
        )
        missing_dates = full_index.difference(df_for_series[st.session_state.time_col])
        if len(missing_dates) > 0:
            st.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã: {len(missing_dates)} —Ç–æ—á–µ–∫. –ß–∞—Å—Ç–æ—Ç–∞: {freq_guess}")
            if st.button("–ó–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã", key="fill_missing_dates"):
                df_tmp = df_for_series.set_index(st.session_state.time_col).reindex(full_index)
                # –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
                for col in cols_to_check:
                    df_tmp[col] = df_tmp[col].interpolate(limit_direction="both")
                    df_tmp[col] = df_tmp[col].fillna(df_tmp[col].mean(skipna=True))
                df_tmp = df_tmp.ffill().bfill()
                df_for_series = df_tmp.reset_index().rename(columns={"index": st.session_state.time_col})
                st.success("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã –∑–∞–ø–æ–ª–Ω–µ–Ω—ã.")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫–∏ + –≤—ã–±–æ—Ä (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è)
    st.subheader("–ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è")
    metric_rec = recommend_metric(series)
    metric_help = {
        "MAE": "–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞, —É—Å—Ç–æ–π—á–∏–≤–∞ –∫ –≤—ã–±—Ä–æ—Å–∞–º –∏ –Ω—É–ª—è–º.",
        "MAPE": "–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è –æ—à–∏–±–∫–∞, —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π, —É–¥–æ–±–Ω–∞ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö.",
        "RMSE": "–ö–æ—Ä–µ–Ω—å –∏–∑ —Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π –æ—à–∏–±–∫–∏, —Å–∏–ª—å–Ω–µ–µ –Ω–∞–∫–∞–∑—ã–≤–∞–µ—Ç –∫—Ä—É–ø–Ω—ã–µ –ø—Ä–æ–º–∞—Ö–∏.",
        "MSE": "–°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞, –∫–≤–∞–¥—Ä–∞—Ç –µ–¥–∏–Ω–∏—Ü, –∂—ë—Å—Ç–∫–æ —à—Ç—Ä–∞—Ñ—É–µ—Ç –±–æ–ª—å—à–∏–µ –æ—à–∏–±–∫–∏.",
    }
    metric_options = list(metric_help.keys())
    recommended_metric = metric_rec["metric"] if metric_rec["metric"] in metric_options else "MAE"

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å—Ç–∞–≤–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—É—é –º–µ—Ç—Ä–∏–∫—É, –ø–æ–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –≤—ã–±—Ä–∞–ª –≤—Ä—É—á–Ω—É—é
    if not st.session_state.get("ranking_metric_user_set"):
        st.session_state.ranking_metric = recommended_metric

    current_metric = (
        st.session_state.ranking_metric
        if st.session_state.ranking_metric in metric_options
        else recommended_metric
    )

    chosen_metric = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç—Ä–∏–∫—É —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π:",
        metric_options,
        index=metric_options.index(current_metric),
        key="ranking_metric_select",
        help="–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–æ–π.",
    )
    if chosen_metric != st.session_state.ranking_metric:
        st.session_state.ranking_metric_user_set = True
    st.session_state.ranking_metric = chosen_metric
    st.info(f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–µ—Ç—Ä–∏–∫–∞: **{recommended_metric}**")
    st.markdown(f"**–ü–æ—è—Å–Ω–µ–Ω–∏–µ:** {metric_rec['reason']}")
    st.caption("\n".join([f"- **{k}**: {v}" for k, v in metric_help.items()]))
    
    # –ì—Ä–∞—Ñ–∏–∫ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏
    st.subheader("üìà –ê–Ω–∞–ª–∏–∑ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏, —Ç—Ä–µ–Ω–¥–∞ –∏ –≤—ã–ø–∞–¥–æ–≤")
    if len(series) < 2 * st.session_state.season_period:
        st.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏. –¢—Ä–µ–±—É–µ—Ç—Å—è –∫–∞–∫ –º–∏–Ω–∏–º—É–º {2 * st.session_state.season_period} —Ç–æ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö (2 –ø–µ—Ä–∏–æ–¥–∞), –∞ —É –≤–∞—Å {len(series)}. –ì—Ä–∞—Ñ–∏–∫ –Ω–µ –±—É–¥–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω.")
    else:
        # –ï—Å–ª–∏ –≥–æ–¥–æ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞ ‚Äî —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –æ–±—ã—á–Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç; –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
        freq_str = str(getattr(series, "freq", "")) if hasattr(series, "freq") else ""
        if freq_str.upper().startswith(("A", "Y")):
            st.info("–ì–æ–¥–æ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞: –≥—Ä–∞—Ñ–∏–∫ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–æ–ø—É—â–µ–Ω.")
        else:
            try:
                fig_decomp = plot_decomposition(series, period=st.session_state.season_period)
                st.plotly_chart(fig_decomp, width='stretch')
            except Exception as e:
                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏: {e}")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π")
    st.session_state.use_hyperopt = st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤", value=st.session_state.use_hyperopt)
    if st.session_state.use_hyperopt:
        st.session_state.n_trials = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥—Ö–æ–¥–æ–≤ –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:", min_value=5, max_value=50, value=st.session_state.n_trials, step=5)
        st.caption("‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.")

    if st.button("üöÄ –ù–∞—á–∞—Ç—å –±–∏—Ç–≤—É –º–æ–¥–µ–ª–µ–π!", type="primary"):
        st.session_state.scroll_to_top = True
        st.session_state.screen = "results"
        st.rerun()

# --- SCREEN 3: RESULTS ---
elif st.session_state.screen == "results":
    # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤
    render_resource_panel(st.session_state.get("run_start_time"))
    # Always ensure we scroll to top when entering results
    components.html(
        """
        <script>
            (() => {
                const goTop = () => {
                    try { window.scrollTo({top: 0, behavior: 'smooth'}); } catch(e) {}
                    try { parent.window.scrollTo({top: 0, behavior: 'smooth'}); } catch(e) {}
                    try { document.documentElement.scrollTo({top: 0, behavior: 'smooth'}); } catch(e) {}
                    try { document.body.scrollTo({top: 0, behavior: 'smooth'}); } catch(e) {}
                };
                requestAnimationFrame(goTop);
                setTimeout(goTop, 50);
                setTimeout(goTop, 150);
            })();
        </script>
        """,
        height=0,
        width=0,
    )
    st.title("–®–∞–≥ 3: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–∏—Ç–≤—ã")

    if st.button("‚Ü©Ô∏è –ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ"):
        reset_session()
        st.rerun()

    if st.session_state.battle_results is None:
        df = st.session_state.df
        time_col = st.session_state.time_col
        value_col = st.session_state.value_col
        n_forecast = st.session_state.n_forecast
        extra_cols = st.session_state.extra_cols
        st.session_state.run_start_time = time.time()
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Å–ª–∞–±—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
        if st.session_state.use_hyperopt and len(df) > 1500:
            st.warning("–ì–∏–ø–µ—Ä–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞ –∏–∑-–∑–∞ –±–æ–ª—å—à–æ–≥–æ –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö. –í–∫–ª—é—á–∏—Ç–µ –≤—Ä—É—á–Ω—É—é —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.")
            st.session_state.use_hyperopt = False
            st.session_state.n_trials = min(st.session_state.n_trials, 10)

        try:
            df_sorted = df.sort_values(by=time_col).reset_index(drop=True)
            cols_to_process = [value_col] + extra_cols
            
            # –û—á–∏—â–∞–µ–º –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            for col in cols_to_process:
                # –£–±–∏—Ä–∞–µ–º –∑–∞–ø—è—Ç—ã–µ, –ø—Ä–æ–±–µ–ª—ã –∏ –¥—Ä—É–≥–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ —Ç—ã—Å—è—á
                if df_sorted[col].dtype == 'object':
                    df_sorted[col] = df_sorted[col].astype(str).str.replace(',', '', regex=False).str.replace(' ', '', regex=False).str.replace('$', '', regex=False)
                df_sorted[col] = pd.to_numeric(df_sorted[col], errors='coerce')
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
            df_sorted.dropna(subset=[value_col], inplace=True)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É –¥–ª—è —ç—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Ç–æ–∂–µ
            df_indexed = df_sorted.set_index(time_col).sort_index()
            inferred_freq = pd.infer_freq(df_indexed.index)
            inferred_freq, monthly_forced = adjust_daily_to_monthly(inferred_freq, df_indexed.index)
            
            if inferred_freq is None and len(df_indexed) > 1:
                time_diffs = df_indexed.index.to_series().diff().dropna()
                if len(time_diffs) > 0:
                    median_diff = time_diffs.median()
                    if pd.Timedelta(hours=23) <= median_diff <= pd.Timedelta(hours=25):
                        inferred_freq = 'D'
                    elif pd.Timedelta(days=27) <= median_diff <= pd.Timedelta(days=32):
                        inferred_freq = 'M'
                    elif pd.Timedelta(hours=11) <= median_diff <= pd.Timedelta(hours=13):
                        inferred_freq = 'H'
            
            inferred_freq, monthly_forced = adjust_daily_to_monthly(inferred_freq, df_indexed.index)
            
            df_sorted = normalize_month_start(df_sorted, time_col, inferred_freq)
            # –°–æ–∑–¥–∞–µ–º TimeSeries —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π
            try:
                if len(df_sorted) >= 3:
                    series = safe_timeseries_from_df(
                        df_sorted,
                        time_col=time_col,
                        value_col=value_col,
                        freq=inferred_freq if inferred_freq else None,
                        label="—Ä–∞—Å—á—ë—Ç–Ω–æ–≥–æ —Ä—è–¥–∞",
                    ).astype(np.float32)
                    
                    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —á–∞—Å—Ç–æ—Ç–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
                    if not hasattr(series, 'freq') or series.freq is None:
                        if inferred_freq:
                            # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º —Ä—è–¥ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π
                            series = TimeSeries.from_times_and_values(
                                series.time_index,
                                series.values(),
                                freq=inferred_freq,
                                fill_missing_dates=True
                            )
                else:
                    st.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –¢—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 3 —Å—Ç—Ä–æ–∫–∏, –∞ —É –≤–∞—Å {len(df_sorted)}.")
                    st.stop()
                    
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞: {e}")
                st.stop()
            
            # FIX: Add a strict check for minimum training size to prevent IndexError
            min_train_size = 10
            max_val_size = len(series) - min_train_size
            if max_val_size <= 0:
                st.error(f"–û—à–∏–±–∫–∞: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –¢—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º {min_train_size + 1} —Ç–æ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö.")
                st.stop()

            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –Ω–∞ –±–æ–ª—å—à–µ–º –æ—Ç—Ä–µ–∑–∫–µ, —á–µ–º horizon, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö —Ö–≤–∞—Ç–∞–µ—Ç
            suggested_val = max(n_forecast, max(5, int(len(series) * 0.2)))
            if max_val_size < n_forecast:
                st.error(f"–û—à–∏–±–∫–∞: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ü–æ—Å–ª–µ –≤—ã–¥–µ–ª–µ–Ω–∏—è {n_forecast} —Ç–æ—á–µ–∫ –ø–æ–¥ –≤–∞–ª–∏–¥–∞—Ü–∏—é –æ—Å—Ç–∞—ë—Ç—Å—è —Ç–æ–ª—å–∫–æ {len(series) - n_forecast}, —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º {min_train_size}. –£–º–µ–Ω—å—à–∏—Ç–µ —Å—Ä–æ–∫ –ø—Ä–æ–≥–Ω–æ–∑–∞ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö.")
                st.stop()
            val_size = min(suggested_val, max_val_size)

            train, val = series[:-val_size], series[-val_size:]
            st.session_state.val_size = val_size
            
            future_covariates = None
            if extra_cols:
                # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –¥–ª—è —ç–∫–∑–æ–≥–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
                exog_df = df_sorted[[time_col] + extra_cols].copy()
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —ç–∫–∑–æ–≥–µ–Ω–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
                for col in extra_cols:
                    # –£–¥–∞–ª—è–µ–º –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Å–ª–∞
                    if exog_df[col].dtype == 'object':
                        exog_df[col] = exog_df[col].astype(str).str.replace(',', '.', regex=False)
                        exog_df[col] = exog_df[col].str.replace(r'[^\d.-]', '', regex=True)
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
                    exog_df[col] = pd.to_numeric(exog_df[col], errors='coerce')
                    
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    exog_df[col].ffill(inplace=True)
                    exog_df[col].bfill(inplace=True)
                    exog_df[col].fillna(0, inplace=True)  # –û—Å—Ç–∞–≤—à–∏–µ—Å—è NaN –∑–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
                
                try:
                    # –°–æ–∑–¥–∞–µ–º TimeSeries –¥–ª—è —ç–∫–∑–æ–≥–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
                    future_covariates = TimeSeries.from_dataframe(
                        exog_df,
                        time_col=time_col,
                        fill_missing_dates=True,
                        freq=inferred_freq if inferred_freq else None
                    ).astype(np.float32)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
                    if not series.time_index.equals(future_covariates.time_index):
                        # –ï—Å–ª–∏ –∏–Ω–¥–µ–∫—Å—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç, –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏—Ö
                        common_time_index = series.time_index.intersection(future_covariates.time_index)
                        if len(common_time_index) == 0:
                            raise ValueError("–í—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ä—è–¥–∞ –∏ —ç–∫–∑–æ–≥–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç.")
                        
                        # –û–±—Ä–µ–∑–∞–µ–º –æ–±–∞ —Ä—è–¥–∞ –¥–æ –æ–±—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                        series = series.slice_intersect(future_covariates)
                        future_covariates = future_covariates.slice_intersect(series)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
                    if future_covariates.n_components != len(extra_cols):
                        raise ValueError(f"–û—à–∏–±–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏: –æ–∂–∏–¥–∞–ª–æ—Å—å {len(extra_cols)} —ç–∫–∑–æ–≥–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö, –ø–æ–ª—É—á–µ–Ω–æ {future_covariates.n_components}")
                    
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–∫–∑–æ–≥–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {e}")
                    st.warning("–ú–æ–¥–µ–ª–∏ –±—É–¥—É—Ç –æ–±—É—á–µ–Ω—ã –±–µ–∑ —É—á–µ—Ç–∞ —ç–∫–∑–æ–≥–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö.")
                    future_covariates = None
                    extra_cols = []
                
                # –î–æ–ø–æ–ª–Ω—è–µ–º —ç–∫–∑–æ–≥–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è)
                if future_covariates is not None and len(future_covariates) < len(series) + n_forecast:
                    try:
                        from utils import _get_ts_values_and_index
                        last_values, last_index = _get_ts_values_and_index(future_covariates)
                        last_vals = last_values[-1] if len(last_values.shape) == 1 else last_values[-1, :]
                        
                        # –°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç—ã
                        if inferred_freq:
                            last_date = last_index[-1]
                            if inferred_freq == 'D':
                                freq_timedelta = pd.Timedelta(days=1)
                            elif inferred_freq == 'M' or inferred_freq.startswith('M'):
                                freq_timedelta = pd.Timedelta(days=30)
                            elif inferred_freq == 'H':
                                freq_timedelta = pd.Timedelta(hours=1)
                            else:
                                freq_timedelta = pd.Timedelta(days=1)
                            
                            needed_dates = len(series) + n_forecast - len(future_covariates)
                            extended_dates = pd.date_range(start=last_date + freq_timedelta, periods=needed_dates, freq=inferred_freq)
                            
                            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è (–¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç–∫–∑–æ–≥–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö)
                            if len(last_vals.shape) == 0:
                                extended_values = np.tile(last_vals, (len(extended_dates),))
                            else:
                                extended_values = np.tile(last_vals, (len(extended_dates), 1))
                            
                            extended_ts = TimeSeries.from_times_and_values(extended_dates, extended_values)
                            future_covariates = future_covariates.concatenate(extended_ts)
                        
                    except Exception as e:
                        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–ø–æ–ª–Ω–∏—Ç—å —ç–∫–∑–æ–≥–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞: {e}")
                        future_covariates = None
                
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å future_covariates, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —ç–∫–∑–æ–≥–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
                if future_covariates is None:
                    extra_cols = []
                    future_covariates = None

            # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
            # –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (—Ä–∞–±–æ—Ç–∞—é—Ç –±–µ–∑ —ç–∫–∑–æ–≥–µ–Ω–Ω—ã—Ö): ExponentialSmoothing, LinearRegression, Prophet, AutoARIMA, LightGBM, Theta, CatBoost, N-HiTS, TCN
            # –°–ª–æ–∂–Ω—ã–µ –º–æ–¥–µ–ª–∏ (—Ç–æ–ª—å–∫–æ —Å —ç–∫–∑–æ–≥–µ–Ω–Ω—ã–º–∏): FFT, N-BEATS –∏ –¥—Ä—É–≥–∏–µ
            base_models = ["ExponentialSmoothing", "LinearRegression", "Prophet", "AutoARIMA", "LightGBM", "Theta", "N-HiTS", "TCN"]
            # –î–æ–±–∞–≤–ª—è–µ–º CatBoost, –µ—Å–ª–∏ –æ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω
            if "CatBoost" in MODELS:
                base_models.append("CatBoost")
            advanced_models = ["FFT", "N-BEATS"]
            
            if extra_cols:
                # –ï—Å–ª–∏ –µ—Å—Ç—å —ç–∫–∑–æ–≥–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏
                models_to_run = {name: mi for name, mi in MODELS.items()}
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç —ç–∫–∑–æ–≥–µ–Ω–Ω—ã—Ö - —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ
                models_to_run = {name: mi for name, mi in MODELS.items() if name in base_models}
            
            results_list, forecasts, trained_models, best_params_dict = [], {}, {}, {}
            total_steps = len(models_to_run) * (2 if st.session_state.use_hyperopt else 1)
            current_step = 0
            
            # –í—ã–≤–æ–¥–∏–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∫–∞–∫ –æ–≤–µ—Ä–ª–µ–π –ø–æ —Ü–µ–Ω—Ç—Ä—É —ç–∫—Ä–∞–Ω–∞
            overlay_placeholder = st.empty()

            def render_overlay(title: str, step_text: str, progress: float):
                percent = int(progress * 100)
                overlay_placeholder.markdown(
                    f"""
                    <div style="
                        position: fixed; inset: 0;
                        background: rgba(0, 0, 0, 0.55);
                        display: flex;
                        align-items: center;
                        justify-content: center;
                        z-index: 9999;">
                        <div style="
                            background: #0b1221;
                            color: #e5e7eb;
                            padding: 22px 26px;
                            border-radius: 18px;
                            width: min(420px, 90%);
                            box-shadow: 0 20px 60px rgba(0,0,0,0.45);
                            font-family: 'Inter', system-ui, -apple-system, sans-serif;">
                            <div style="display: flex; align-items: center; justify-content: space-between; margin-bottom: 12px;">
                                <span style="font-size: 18px; font-weight: 700;">{title}</span>
                                <span style="font-size: 14px; opacity: 0.8;">{percent}%</span>
                            </div>
                            <div style="font-size: 14px; margin-bottom: 12px; line-height: 1.5;">{step_text}</div>
                            <div style="background: rgba(255,255,255,0.08); border-radius: 999px; height: 12px; overflow: hidden;">
                                <div style="
                                    width: {percent}%;
                                    height: 100%;
                                    background: linear-gradient(90deg, #22d3ee, #6366f1);
                                    transition: width 180ms ease-out;"></div>
                            </div>
                        </div>
                    </div>
                    """,
                    unsafe_allow_html=True,
                )

            render_overlay("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π", "‚è≥ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ–±—É—á–µ–Ω–∏—é...", 0)
            
            for name, model_info in models_to_run.items():
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ —Å —ç–∫–∑–æ–≥–µ–Ω–Ω—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
                if model_info["requires_extras"] and not extra_cols:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä–µ–±—É—é—Ç —ç–∫–∑–æ–≥–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
                    continue
                
                # –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
                best_params = None
                if st.session_state.use_hyperopt:
                    current_step += 1
                    progress = current_step / total_steps
                    render_overlay(
                        "–ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤",
                        f"üîç {name}: –ø–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ ({current_step}/{total_steps})",
                        progress,
                    )
                    best_params, opt_error = optimize_hyperparameters(
                        model_name=name,
                        train_series=train,
                        val_series=val,
                        forecast_horizon=len(val),
                        future_covariates=future_covariates,
                        n_trials=st.session_state.n_trials,
                        metric=st.session_state.ranking_metric.lower(),
                        season_length=st.session_state.season_period,
                    )
                    if opt_error:
                        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å {name}: {opt_error}. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
                    else:
                        best_params_dict[name] = best_params
                
                # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                current_step += 1
                progress = current_step / total_steps
                render_overlay(
                    "–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π",
                    f"üöÄ {name}: –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è ({current_step}/{total_steps})",
                    progress,
                )
                
                forecast, model, error = train_model(
                    model_name=name, 
                    train_series=train,
                    forecast_horizon=len(val), 
                    future_covariates=future_covariates,
                    model_params=best_params if best_params else None,
                    season_length=st.session_state.season_period,
                )

                if error or forecast is None:
                    results_list.append({"–ú–æ–¥–µ–ª—å": name, "MAPE": np.nan, "MAE": np.nan, "RMSE": np.nan, "MSE": np.nan, "R2": np.nan, "–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã": error or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"})
                    continue

                # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω—É–ª–µ–π
                # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏, –≤—ã—Ä–∞–≤–Ω–∏–≤–∞—è —Ä—è–¥—ã –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–µ –∏ —É–±–∏—Ä–∞—è NaN
                from utils import _get_ts_values_and_index
                val_values, _ = _get_ts_values_and_index(val)
                fc_values, _ = _get_ts_values_and_index(forecast)
                min_len = min(len(val_values), len(fc_values))
                if min_len == 0:
                    mape_score = mae_score = r2_score_val = rmse_score = mse_score = np.nan
                else:
                    v_arr = val_values[:min_len].astype(float)
                    f_arr = fc_values[:min_len].astype(float)
                    mask = np.isfinite(v_arr) & np.isfinite(f_arr)
                    v_arr = v_arr[mask]
                    f_arr = f_arr[mask]
                    if len(v_arr) == 0:
                        mape_score = mae_score = r2_score_val = rmse_score = mse_score = np.nan
                    else:
                        # –ø—Ä–æ—Å—Ç—ã–µ numpy-–º–µ—Ç—Ä–∏–∫–∏
                        mae_score = float(np.mean(np.abs(v_arr - f_arr)))
                        mse_score = float(np.mean((v_arr - f_arr) ** 2))
                        rmse_score = float(np.sqrt(mse_score))
                        if 0 in v_arr:
                            mape_score = np.nan
                        else:
                            mape_score = float(np.mean(np.abs((v_arr - f_arr) / v_arr)) * 100)
                        var = np.var(v_arr)
                        if var == 0:
                            r2_score_val = np.nan
                        else:
                            ss_res = np.sum((v_arr - f_arr) ** 2)
                            ss_tot = np.sum((v_arr - np.mean(v_arr)) ** 2)
                            r2_score_val = 1 - ss_res / ss_tot if ss_tot != 0 else np.nan
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö
                if best_params:
                    params_str = f"–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ: {best_params}"
                else:
                    try:
                        params = model.model_params if hasattr(model, 'model_params') else getattr(model, 'model', {}).get_params() if hasattr(model, 'model') else {}
                        params_str = str(params) if params else "–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é"
                    except:
                        params_str = "–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é"
                
                results_list.append({"–ú–æ–¥–µ–ª—å": name, "MAPE": mape_score, "MAE": mae_score, "RMSE": rmse_score, "MSE": mse_score, "R2": r2_score_val, "–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã": params_str})
                forecasts[name] = forecast
                trained_models[name] = model
            
            overlay_placeholder.empty()  # –£–±–∏—Ä–∞–µ–º –æ–≤–µ—Ä–ª–µ–π –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            st.success("‚úÖ –û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

            if not results_list:
                overlay_placeholder.empty()
                st.error("–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ —Å–º–æ–≥–ª–∞ –±—ã—Ç—å –æ–±—É—á–µ–Ω–∞."); st.stop()

            results_df = pd.DataFrame(results_list).set_index("–ú–æ–¥–µ–ª—å")
            # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –≤—Å—è NaN, –ø—Ä–æ–±—É–µ–º –ø–æ–¥–æ–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é, –Ω–æ –Ω–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            metric_priority = ["MAE", "RMSE", "MAPE", "MSE"]
            non_nan_metrics = [m for m in metric_priority if m in results_df.columns and results_df[m].notna().any()]
            if not non_nan_metrics:
                st.warning("–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–ª–∞ –º–µ—Ç—Ä–∏–∫–∏ (–≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è NaN). –ü–æ–∫–∞–∑–∞–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∫ –µ—Å—Ç—å. –ù–∏–∂–µ –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –ø–æ –º–æ–¥–µ–ª—è–º.")
                st.dataframe(results_df.reset_index())  # –≤—ã–≤–æ–¥–∏–º —Å—ã—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –æ—à–∏–±–∫–∞–º–∏
                st.session_state.ranking_metric = metric_priority[0]
            elif not results_df[st.session_state.ranking_metric].notna().any():
                fallback_metric = non_nan_metrics[0]
                st.warning(f"–ú–µ—Ç—Ä–∏–∫–∞ {st.session_state.ranking_metric} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (–≤—Å–µ NaN). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {fallback_metric}.")
                st.session_state.ranking_metric = fallback_metric
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –≤ –∫–∞–∫–æ–º –ø–æ—Ä—è–¥–∫–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å:
            # –¥–ª—è R2 –∏ RMSE –ø–æ —É–±—ã–≤–∞–Ω–∏—é (–±–æ–ª—å—à–µ –ª—É—á—à–µ), –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é.
            ascending_flag = False if st.session_state.ranking_metric == "R2" else True


            results_df = results_df.sort_values(
                by=st.session_state.ranking_metric,
                ascending=ascending_flag,
                na_position='last'
            )
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥
            non_na_results = results_df.dropna(subset=[st.session_state.ranking_metric])
            if non_na_results.empty:
                st.error("–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–ª–∞ –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–µ—Ç—Ä–∏–∫—É (–≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è NaN). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é –º–µ—Ç—Ä–∏–∫—É –∏–ª–∏ –¥—Ä—É–≥–æ–π –≥–æ—Ä–∏–∑–æ–Ω—Ç.")
                st.stop()
            best_model_name = non_na_results.index[0]
            best_model = trained_models.get(best_model_name)
            final_forecast = None
            
            if best_model is not None:
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏
                    model_params = best_params_dict.get(best_model_name, {})
                    
                    # –û–±—É—á–∞–µ–º –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º –Ω–∞ n_forecast —à–∞–≥–æ–≤ –≤–ø–µ—Ä–µ–¥
                    forecast_result, _, error = train_model(
                        model_name=best_model_name,
                        train_series=series,
                        forecast_horizon=n_forecast,
                        future_covariates=future_covariates,
                        model_params=model_params if model_params else None,
                        season_length=st.session_state.season_period,
                    )
                    if not error and forecast_result is not None:
                        final_forecast = forecast_result
                except Exception as e:
                    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑: {e}")
            
            st.session_state.battle_results = results_df
            st.session_state.forecasts = forecasts
            st.session_state.trained_models = trained_models
            st.session_state.final_forecast = final_forecast

        except Exception as e:
            if "overlay_placeholder" in locals():
                overlay_placeholder.empty()
            st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
            st.exception(e)
            st.stop()

    results_df = st.session_state.battle_results
    forecasts = st.session_state.forecasts
    
    st.subheader(f"üèÜ –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {st.session_state.n_forecast} —à–∞–≥–æ–≤)")
    st.markdown(f"–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ: **{st.session_state.ranking_metric}**")

    def highlight_best(s):
        is_min = s.name in ["MAE", "MAPE", "RMSE", "MSE"]
        best_val = s.min() if is_min else s.max()
        return ['background-color: #28a745' if v == best_val else '' for v in s]

    st.dataframe(
        results_df.style.apply(
            highlight_best,
            subset=["MAE", "MAPE", "RMSE", "MSE", "R2"]
        ).format(
            {"MAPE": "{:.4f}", "MAE": "{:.4f}", "RMSE": "{:.4f}", "MSE": "{:.4f}", "R2": "{:.4f}"},
            na_rep="-"
        )
    )

    # –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    st.subheader("üìä –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    successful_models = list(forecasts.keys())
    if successful_models:
        default_models = results_df.dropna(subset=[st.session_state.ranking_metric]).head(3).index.tolist()
        
        models_to_plot = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è:", successful_models, default=default_models)
        
        if models_to_plot:
            df_for_plot = st.session_state.df.sort_values(by=st.session_state.time_col).copy()
            df_for_plot[st.session_state.value_col] = pd.to_numeric(df_for_plot[st.session_state.value_col], errors='coerce')
            df_for_plot.dropna(subset=[st.session_state.value_col], inplace=True)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ —Ç–æ–∂–µ
            df_plot_indexed = df_for_plot.set_index(st.session_state.time_col).sort_index()
            plot_freq = pd.infer_freq(df_plot_indexed.index)
            if plot_freq is None and len(df_plot_indexed) > 1:
                time_diffs = df_plot_indexed.index.to_series().diff().dropna()
                if len(time_diffs) > 0:
                    median_diff = time_diffs.median()
                    if pd.Timedelta(hours=23) <= median_diff <= pd.Timedelta(hours=25):
                        plot_freq = 'D'
                    elif pd.Timedelta(days=27) <= median_diff <= pd.Timedelta(days=32):
                        plot_freq = 'M'
                    elif pd.Timedelta(hours=11) <= median_diff <= pd.Timedelta(hours=13):
                        plot_freq = 'H'

            # Ensure the time column is in datetime format
            time_col = st.session_state.time_col
            value_col = st.session_state.value_col
            
            # Make a copy to avoid modifying the original
            plot_df = df_for_plot[[time_col, value_col]].copy()
            
            # Convert to datetime if not already
            if not pd.api.types.is_datetime64_any_dtype(plot_df[time_col]):
                plot_df[time_col] = pd.to_datetime(plot_df[time_col], errors='coerce')
            
            # Set the time column as index
            plot_df = plot_df.set_index(time_col).sort_index()
            
            plot_freq, plot_monthly_forced = adjust_daily_to_monthly(plot_freq, plot_df.index)

            # Try to infer frequency if not provided
            if not plot_freq:
                try:
                    plot_freq = pd.infer_freq(plot_df.index)
                    if not plot_freq:  # If frequency couldn't be inferred
                        # Calculate median time difference
                        time_diffs = plot_df.index.to_series().diff().dropna()
                        if not time_diffs.empty:
                            median_diff = time_diffs.median()
                            if pd.Timedelta(days=27) <= median_diff <= pd.Timedelta(days=33):
                                plot_freq = 'M'  # Monthly
                            elif median_diff >= pd.Timedelta(days=80) and median_diff <= pd.Timedelta(days=100):
                                plot_freq = 'Q'  # Quarterly
                            elif median_diff >= pd.Timedelta(days=300) and median_diff <= pd.Timedelta(days=400):
                                plot_freq = 'A'  # Yearly
                            elif median_diff <= pd.Timedelta(hours=2):
                                plot_freq = 'H'  # Hourly
                            else:
                                plot_freq = 'D'  # Daily as fallback
                except Exception:
                    plot_freq = None
            
            # Create TimeSeries with inferred frequency
            plot_df_reset = normalize_month_start(plot_df.reset_index(), time_col, plot_freq)
            series_to_plot = safe_timeseries_from_df(
                plot_df_reset,
                time_col=time_col,
                value_col=value_col,
                freq=plot_freq,
                label="–≥—Ä–∞—Ñ–∏–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞",
            ).astype(np.float32)
            val_size_plot = st.session_state.get("val_size", st.session_state.n_forecast)
            train_plot, val_plot = series_to_plot[:-val_size_plot], series_to_plot[-val_size_plot:]
            
            selected_forecasts = {name: forecasts[name] for name in models_to_plot if name in forecasts}
            fig_test = plot_forecast(train_plot, val_plot, selected_forecasts)
            st.plotly_chart(fig_test, width='stretch')
    else:
        st.warning("–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ —Å–º–æ–≥–ª–∞ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑, –≥—Ä–∞—Ñ–∏–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
    
    # –ì—Ä–∞—Ñ–∏–∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    st.subheader("üéØ –§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –Ω—É–∂–Ω—ã–π –ø–µ—Ä–∏–æ–¥ (–ª—É—á—à–∞—è –º–æ–¥–µ–ª—å)")
    non_na_results = results_df.dropna(subset=[st.session_state.ranking_metric])
    if non_na_results.empty:
        st.warning("–§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –Ω–µ—Ç –º–æ–¥–µ–ª–µ–π —Å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω–æ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–æ–π.")
    else:
        best_model_name = non_na_results.index[0]
    if st.session_state.final_forecast is not None and non_na_results is not None and not non_na_results.empty:
        time_col = st.session_state.time_col
        value_col = st.session_state.value_col
        
        # Prepare the final data
        df_for_final = st.session_state.df.sort_values(by=time_col).copy()
        df_for_final[value_col] = pd.to_numeric(df_for_final[value_col], errors='coerce')
        df_for_final.dropna(subset=[value_col], inplace=True)
        
        # Make a copy to avoid modifying the original
        plot_df = df_for_final[[time_col, value_col]].copy()
        
        # Convert to datetime if not already
        if not pd.api.types.is_datetime64_any_dtype(plot_df[time_col]):
            plot_df[time_col] = pd.to_datetime(plot_df[time_col], errors='coerce')
        
        # Remove any rows with NaT in the time column
        plot_df = plot_df.dropna(subset=[time_col])
        
        # Set the time column as index and sort
        plot_df = plot_df.set_index(time_col).sort_index()
        
        # Try to infer frequency
        final_freq = pd.infer_freq(plot_df.index)
        
        if not final_freq and len(plot_df) > 1:
            # Calculate median time difference
            time_diffs = plot_df.index.to_series().diff().dropna()
            if not time_diffs.empty:
                median_diff = time_diffs.median()
                if pd.Timedelta(days=23) <= median_diff <= pd.Timedelta(days=33):
                    final_freq = 'M'  # Monthly
                elif pd.Timedelta(hours=11) <= median_diff <= pd.Timedelta(hours=13):
                    final_freq = 'H'  # Hourly
                elif pd.Timedelta(hours=23) <= median_diff <= pd.Timedelta(hours=25):
                    final_freq = 'D'  # Daily
                elif pd.Timedelta(days=80) <= median_diff <= pd.Timedelta(days=100):
                    final_freq = 'Q'  # Quarterly
                elif pd.Timedelta(days=300) <= median_diff <= pd.Timedelta(days=400):
                    final_freq = 'A'  # Yearly

        final_freq, final_monthly_forced = adjust_daily_to_monthly(final_freq, plot_df.index)
        
        # Create TimeSeries with inferred frequency
        try:
            plot_df_reset = normalize_month_start(plot_df.reset_index(), time_col, final_freq)
            series_full = safe_timeseries_from_df(
                plot_df_reset,
                time_col=time_col,
                value_col=value_col,
                freq=final_freq if final_freq else None,
                label="—Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞",
            ).astype(np.float32)
        except Exception as e:
            # Fallback without frequency if there's an error
            st.warning(f"Could not set frequency for final forecast plot: {e}. Plotting without frequency.")
            series_full = TimeSeries.from_dataframe(
                plot_df_reset,
                time_col=time_col,
                value_cols=value_col,
                fill_missing_dates=False
            ).astype(np.float32)
        
        fig_final = plot_final_forecast(series_full, st.session_state.final_forecast)
        st.plotly_chart(fig_final, width='stretch')
        
        # –í—ã–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        st.subheader("üì• –í—ã–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        col1, col2, col3 = st.columns(3)
        with col1:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º TimeSeries –≤ DataFrame –¥–ª—è CSV
            from utils import _get_ts_dataframe
            forecast_df = _get_ts_dataframe(st.session_state.final_forecast)
            st.download_button(
                "–°–∫–∞—á–∞—Ç—å CSV (–ø—Ä–æ–≥–Ω–æ–∑)", 
                forecast_df.to_csv(index=True).encode("utf-8"), 
                f"forecast_{best_model_name}.csv", 
                "text/csv"
            )
        with col2:
            st.download_button(
                "–°–∫–∞—á–∞—Ç—å XLSX (–ø—Ä–æ–≥–Ω–æ–∑)", 
                create_excel_download(st.session_state.final_forecast), 
                f"forecast_{best_model_name}.xlsx", 
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    else:
        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏.")
